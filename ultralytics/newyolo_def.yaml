# Ultralytics YOLO ðŸš€, AGPL-3.0 license
# YOLOv6 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/models/yolov6

#Quantization parameters
act_bit_width: &act_bit_width 6
weight_bit_width: &weight_bit_width 6

conv_params: &conv_params {weight_quant: Int8WeightPerChannelPoT, weight_bit_width: *weight_bit_width, return_quant_tensor: True, act_quant: Uint8ActPerTensorPoT, bit_width: *act_bit_width}
#conv_params: &conv_params {}
  

# Parameters
nc: 80  # number of classes
activation: qnn.QuantReLU()  # (optional) model default activation function
scales: # model compound scaling constants, i.e. 'model=yolov6n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.167, 0.25, 1024]
  #n: [0.33, 0.25, 1024]
  s: [0.33, 0.50, 1024]
  m: [0.67, 0.75, 768]
  l: [1.00, 1.00, 512]
  x: [1.00, 1.25, 512]

# YOLOv6-3.0s backbone
backbone:
  # [from, repeats, module, args,kwargs]
  #- [-1, 1, qnn.QuantIdentity, [],{ return_quant_tensor: False, act_quant: Uint8ActPerTensorPoT, bit_width: *act_bit_width}]  # 0-P1/2

  - [-1, 1, QuantConv, [64, 3, 2],*conv_params]  # 0-P1/2
  - [-1, 1, QuantConv, [128, 3, 2],*conv_params]  # 1-P2/4
  - [-1, 6, QuantConv, [128, 3, 1],*conv_params]
  - [-1, 1, QuantConv, [256, 3, 2],*conv_params]  # 3-P3/8
  - [-1, 12, QuantConv, [256, 3, 1],*conv_params]
  - [-1, 1, QuantConv, [512, 3, 2],*conv_params]  # 5-P4/16
  - [-1, 18, QuantConv, [512, 3, 1],*conv_params]
  - [-1, 1, QuantConv, [1024, 3, 2],*conv_params]  # 7-P5/32
  - [-1, 6, QuantConv, [1024, 3, 1],*conv_params]
  - [-1, 1, QuantSPPF, [1024, 5],*conv_params]  # 9
  # - [-1, 1, SPP, [1024, [5, 9, 13]]]  # 9

# YOLOv6-3.0s head
head:
  - [-1, 1, QuantConv, [256, 1, 1],*conv_params]
  - [-1, 1, QuantUpsamplingNearest2d, [None, 2],{return_quant_tensor: True}] # - [-1, 1, Conv, [256, 1, 1]]
  #- [-1, 1, QuantConvTranspose, [256, 2, 2, 0]]
  - [[-1, 6], 1, QuantConcat, [1],{}]  # cat backbone P4
  - [-1, 1, QuantConv, [256, 3, 1],*conv_params]
  - [-1, 9, QuantConv, [256, 3, 1],*conv_params]  # 14

  - [-1, 1, QuantConv, [128, 1, 1],*conv_params]
  - [-1, 1, QuantUpsamplingNearest2d, [None, 2],{return_quant_tensor: True}] # - [-1, 1, Conv, [256, 1, 1]]
  #- [-1, 1, QuantConvTranspose, [128, 2, 2, 0]]
  - [[-1, 4], 1, QuantConcat, [1],{  }]  # cat backbone P3
  - [-1, 1, QuantConv, [128, 3, 1],*conv_params]
  - [-1, 9, QuantConv, [128, 3, 1],*conv_params]  # 19

  - [-1, 1, QuantConv, [128, 3, 2],*conv_params]
  - [[-1, 15], 1, QuantConcat, [1],{  }]  # cat head P4
  - [-1, 1, QuantConv, [256, 3, 1],*conv_params]
  - [-1, 9, QuantConv, [256, 3, 1],*conv_params]  # 23

  - [-1, 1, QuantConv, [256, 3, 2],*conv_params]
  - [[-1, 10], 1, QuantConcat, [1],{  }]  # cat head P5
  - [-1, 1, QuantConv, [512, 3, 1],*conv_params]
  - [-1, 9, QuantConv, [512, 3, 1],*conv_params]  # 27
  - [[19, 23, 27], 1, QuantDetect, [nc],*conv_params]  # Detect(P3, P4, P5)
  #- [-1, 1, qnn.QuantIdentity, [],{ return_quant_tensor: True, act_quant: Int8ActPerTensorPoT, bit_width: *act_bit_width}]  # 0-P1/2
#  - [-1,1, QuantUnpackTensors, [0],{}]  # 28
#  - [-1,1, PostQuantDetect, [nc],{}]  # 29
  # - [[4], 1, Detect, [nc]]  # Detect(P3, P4, P5)